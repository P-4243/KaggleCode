{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12b66e6a-a13a-4932-89de-e6dda4a800ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\sophi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\sophi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\sophi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\sophi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\sophi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\sophi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sophi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sophi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2025.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\sophi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sophi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\sophi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\sophi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sophi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c24f5bd-535d-4a24-9346-c5222899f828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms, models\n",
    "from tqdm import tqdm  # For showing the progress bar\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ecb33cb-caaa-4129-adf5-3bf930d8132a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e015def-ae54-4f4f-8a17-00800fea79da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cpu\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)  # Should print the installed PyTorch version\n",
    "print(torch.cuda.is_available())  # Should return True if GPU is available, False otherwise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "297cdaaf-e0eb-4acd-ac72-85dc8727c9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\sophi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.67.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "344f745b-d215-4851-ad1a-8c4bfd7d1126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tqdm is installed successfully!\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "print(\"tqdm is installed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6dac3da-4d65-46c1-a10c-6bdce63405f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a249d92-590c-48df-a7ba-ebd24f693bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full dataset and split into train and validation sets\n",
    "dataset = datasets.ImageFolder(root='dataset/preprocessedDataset', transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8a74b2e-d1e8-437c-9754-e6fc327d9042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2b79d7a-ad82-4f7e-a8f6-6e23f9b6944d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sophi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sophi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Epoch 1/50: 100%|█████████████████████████████████████████| 194/194 [42:36<00:00, 13.18s/it, loss=1.02, accuracy=0.677]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Train Loss: 1.0205, Train Accuracy: 0.6770, Val Loss: 0.8569, Val Accuracy: 0.7203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|█████████████████████████████████████████| 194/194 [55:01<00:00, 17.02s/it, loss=0.496, accuracy=0.84]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "Train Loss: 0.4960, Train Accuracy: 0.8402, Val Loss: 1.0496, Val Accuracy: 0.7087\n",
      "Early stopping counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|████████████████████████████████████████| 194/194 [29:05<00:00,  9.00s/it, loss=0.287, accuracy=0.907]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50\n",
      "Train Loss: 0.2869, Train Accuracy: 0.9074, Val Loss: 0.6590, Val Accuracy: 0.8049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|████████████████████████████████████████| 194/194 [14:38<00:00,  4.53s/it, loss=0.228, accuracy=0.923]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50\n",
      "Train Loss: 0.2283, Train Accuracy: 0.9231, Val Loss: 0.4597, Val Accuracy: 0.8650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|████████████████████████████████████████| 194/194 [14:23<00:00,  4.45s/it, loss=0.173, accuracy=0.943]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "Train Loss: 0.1732, Train Accuracy: 0.9434, Val Loss: 0.4732, Val Accuracy: 0.8689\n",
      "Early stopping counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|████████████████████████████████████████| 194/194 [16:08<00:00,  4.99s/it, loss=0.159, accuracy=0.948]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50\n",
      "Train Loss: 0.1592, Train Accuracy: 0.9476, Val Loss: 1.1487, Val Accuracy: 0.7242\n",
      "Early stopping counter: 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|████████████████████████████████████████| 194/194 [15:24<00:00,  4.77s/it, loss=0.111, accuracy=0.964]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n",
      "Train Loss: 0.1106, Train Accuracy: 0.9643, Val Loss: 0.2683, Val Accuracy: 0.9160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: 100%|███████████████████████████████████████| 194/194 [47:42<00:00, 14.75s/it, loss=0.0817, accuracy=0.973]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50\n",
      "Train Loss: 0.0817, Train Accuracy: 0.9735, Val Loss: 0.4252, Val Accuracy: 0.8844\n",
      "Early stopping counter: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: 100%|███████████████████████████████████████| 194/194 [32:36<00:00, 10.09s/it, loss=0.0954, accuracy=0.967]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "Train Loss: 0.0954, Train Accuracy: 0.9672, Val Loss: 0.5048, Val Accuracy: 0.8598\n",
      "Early stopping counter: 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: 100%|█████████████████████████████████████| 194/194 [1:17:56<00:00, 24.11s/it, loss=0.097, accuracy=0.969]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "Train Loss: 0.0970, Train Accuracy: 0.9691, Val Loss: 0.3421, Val Accuracy: 0.9134\n",
      "Early stopping counter: 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50: 100%|████████████████████████████████████| 194/194 [1:25:38<00:00, 26.49s/it, loss=0.0903, accuracy=0.972]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50\n",
      "Train Loss: 0.0903, Train Accuracy: 0.9716, Val Loss: 0.3910, Val Accuracy: 0.8882\n",
      "Early stopping counter: 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50: 100%|████████████████████████████████████████| 194/194 [37:35<00:00, 11.63s/it, loss=0.098, accuracy=0.97]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50\n",
      "Train Loss: 0.0980, Train Accuracy: 0.9703, Val Loss: 0.4177, Val Accuracy: 0.9031\n",
      "Early stopping counter: 5/5\n",
      "No improvement for several epochs. Triggering early stopping.\n",
      "Early stopping triggered. Stopping training.\n"
     ]
    }
   ],
   "source": [
    "# Define the CNN model\n",
    "class PestDetectionCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(PestDetectionCNN, self).__init__()\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Initialize model\n",
    "num_classes = len(dataset.classes)\n",
    "model = PestDetectionCNN(num_classes).to(device)\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Function to calculate accuracy\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "    _, predicted = torch.max(y_pred, 1)\n",
    "    return (predicted == y_true).float().mean().item()\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 5  # Number of epochs to wait for improvement before stopping\n",
    "best_val_loss = float('inf')\n",
    "early_stop_counter = 0\n",
    "early_stopping = False\n",
    "\n",
    "# Train the model with early stopping\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    if early_stopping:\n",
    "        print(\"Early stopping triggered. Stopping training.\")\n",
    "        break\n",
    "\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    # Training loop with progress bar\n",
    "    progress_bar = tqdm.tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    for i, (images, labels) in enumerate(progress_bar):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update running loss and accuracy\n",
    "        running_loss += loss.item()\n",
    "        correct_predictions += (outputs.argmax(1) == labels).sum().item()\n",
    "        total_predictions += labels.size(0)\n",
    "\n",
    "        # Update progress bar description\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': running_loss / (i + 1),\n",
    "            'accuracy': correct_predictions / total_predictions\n",
    "        })\n",
    "        # Validation step\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_val_predictions = 0\n",
    "    total_val_predictions = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            correct_val_predictions += (outputs.argmax(1) == labels).sum().item()\n",
    "            total_val_predictions += labels.size(0)\n",
    "\n",
    "    # Calculate validation metrics\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = correct_val_predictions / total_val_predictions\n",
    "\n",
    "    # Print epoch summary\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {running_loss / len(train_loader):.4f}, \"\n",
    "          f\"Train Accuracy: {correct_predictions / total_predictions:.4f}, \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    # Early stopping logic\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        early_stop_counter = 0  # Reset counter if validation loss improves\n",
    "        torch.save(model.state_dict(), 'best_pest_detection_model.pth')  # Save the best model\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        print(f\"Early stopping counter: {early_stop_counter}/{patience}\")\n",
    "        if early_stop_counter >= patience:\n",
    "            print(\"No improvement for several epochs. Triggering early stopping.\")\n",
    "            early_stopping = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29934b6c-4996-4691-a594-31c9c82d8d71",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Save the trained model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpest_detection_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'pest_detection_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f14b6e0e-a32a-451d-9c0a-4df575edd1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0833, Train Accuracy: 0.9743\n"
     ]
    }
   ],
   "source": [
    "# Function to evaluate the model on a given dataset\n",
    "def evaluate_model(loader, model, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "             # Calculate loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            correct_predictions += (outputs.argmax(1) == labels).sum().item()\n",
    "            total_predictions += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# Evaluate on training data\n",
    "train_loss, train_accuracy = evaluate_model(train_loader, model, criterion, device)\n",
    "print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a57cfe8-81a7-4d87-87c3-3a7f3f1599bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0824, Validation Accuracy: 0.9767\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation data\n",
    "val_loss, val_accuracy = evaluate_model(val_loader, model, criterion, device)\n",
    "print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2780a979-8164-40a3-a3ad-06710060106f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp310-cp310-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\sophi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\sophi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.6.1-cp310-cp310-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.1 MB 2.4 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 1.0/11.1 MB 2.2 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 1.6/11.1 MB 2.4 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 2.1/11.1 MB 2.4 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 2.9/11.1 MB 2.6 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 3.7/11.1 MB 2.9 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 4.7/11.1 MB 3.1 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 5.5/11.1 MB 3.2 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 6.3/11.1 MB 3.3 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.1/11.1 MB 3.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.1/11.1 MB 3.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.2/11.1 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.2/11.1 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 3.7 MB/s eta 0:00:00\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.1 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51c772a3-2505-4626-8ec0-45f1eba84c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# Assuming you have a dataset object like `train_dataset`\n",
    "dataset_size = len(train_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "\n",
    "# Split the indices into training and test sets (e.g., 80% train, 20% test)\n",
    "train_indices, test_indices = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create subsets for train and test data\n",
    "train_subset = Subset(train_dataset, train_indices)\n",
    "test_subset = Subset(train_dataset, test_indices)# Create DataLoader for train and test subsets\n",
    "train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_subset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b1d8892-f7f5-4901-8cf5-1006a058f99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0876, Test Accuracy: 0.9766\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test data\n",
    "test_loss, test_accuracy = evaluate_model(test_loader, model, criterion, device)\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6634bb51-de75-48f2-b47b-a5c2d443b548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "# Function to download and preprocess the image\n",
    "def preprocess_image_from_url(url, transform):\n",
    "    response = requests.get(url)\n",
    "    image = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    return image\n",
    "\n",
    "# Define your image transformation pipeline (same as before)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Example URL of the image\n",
    "image_url = \"https://th.bing.com/th/id/OIP.DHzBfQKXXFZj8o70V0EjSgHaF9?rs=1&pid=ImgDetMain\"\n",
    "image_tensor = preprocess_image_from_url(image_url, transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7fc3cc8-44fc-442b-b40e-b11e867317e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 10\n"
     ]
    }
   ],
   "source": [
    "# Assuming your model is already defined and loaded\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Move image tensor to the appropriate device\n",
    "image_tensor = image_tensor.to(device)\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    outputs = model(image_tensor)\n",
    "\n",
    "# Process outputs to get the predicted class\n",
    "_, predicted_class = torch.max(outputs, 1)\n",
    "print(f\"Predicted class: {predicted_class.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656d47d3-6311-480b-8cc9-2fc05098f713",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
